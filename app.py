import streamlit as st
import pandas as pd
from docx import Document
from io import BytesIO
from openai import OpenAI
import re

# ---------- ูุงุฌูุฉ ุงูุชุทุจูู ----------
st.set_page_config(page_title="ูุดุงูุงุช ุนูููุฉ ูุน ุฑูู ุงูุตูุญุฉ", layout="wide")
st.title("๐ ุงุณุชุฎุฑุงุฌ ุงููุดุงูุงุช ุงูุนูููุฉ ูู ูุต ูุงูู ูุดูุฎ ุงูุฅุณูุงู ุงุจู ุชูููุฉ")

# ---------- ุฅุฏุฎุงู ุงูุจูุงูุงุช ----------
openai_key = st.text_input("๐ ุฃุฏุฎู ููุชุงุญ OpenAI", type="password")
model_choice = st.selectbox("๐ง ุงุฎุชุฑ ุงููููุฐุฌ", ["gpt-4", "gpt-3.5-turbo"])
uploaded_file = st.file_uploader("๐ ุงุฑูุน ููู ููุฑุฏ ูุญุชูู ุนูู ุงููุต ุงููุงูู", type=["docx"])

if "excel_output" not in st.session_state:
    st.session_state.excel_output = None

# ---------- ุงุณุชุฎุฑุงุฌ ุงููุต ุงููุงูู ูู Word ----------
def extract_full_text(docx_file):
    doc = Document(docx_file)
    full_text = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
    return full_text

# ---------- ุชูููุฏ ุงูุจุฑููุจุช ----------
def generate_prompt(text):
    return f"""
ุงูุฑุฃ ุงููุต ุงูุชุงูู ูู ูุชุงุจ ูุดูุฎ ุงูุฅุณูุงู ุงุจู ุชูููุฉุ ูุงุณุชุฎุฑุฌ ููุท ุงูููุฑุงุช ุฃู ุงูููุงุถุน ุงูุชู ุชุฑู ุฃููุง ุชุญุชูู ุนูู ูุดุงู ุนููู ูู ุงูุฃููุงุน ุงูุชุงููุฉ:

1. ุชูุณูุฑ ุงูุขูุงุช
2. ุดุฑูุญ ุงูุฃุญุงุฏูุซ
3. ุงูุฃุญูุงู ุงูุญุฏูุซูุฉ
4. ุงูุฅุฌูุงุน
5. ุงูุฎูุงู
6. ุงูุชุฑุฌูุญ
7. ุงูููุงุนุฏ ูุงูุถูุงุจุท ูุงููุฑูู ูุงูุชูุงุณูู
8. ุงูููุงูู ุงูุดุฎุตูุฉ

๐น ููู ูุดุงูุ ุฃุฎุฑุฌ ุงููุชุงุฆุฌ ุจุตูุบุฉ ุฌุฏูู ูุญุชูู ุนูู ุงูุฃุนูุฏุฉ ุงูุชุงููุฉ:
- ูุทูุน ุงูููุฑุฉ ุฃู ุฌููุฉ ูุตูุฑุฉ ุชูุซู ูููุน ุงููุดุงู
- ููุน ุงููุดุงู (ูู ุงููุงุฆูุฉ ุฃุนูุงู)
- ุนููุงู ุงููุดุงู ุงูููุงุณุจ
- ุณุจุจ ุงูุชุตููู (ููุงุฐุง ุตููุชูุง ุถูู ูุฐุง ุงููุดุงู)

๐ธ ูุง ุชูุฎุฑุฌ ุฅูุง ุงูููุงุถุน ุงูุชู ุชุญุชูู ูุดุงููุง ูุนูููุงุ ููุง ุชููุฎูุต ุฃู ุชูุนูู ุนูู ุจููุฉ ุงููุต.

ุงููุต ุงููุงูู:
{text}
"""

# ---------- ุชุญููู ุงููุต ุจุงุณุชุฎุฏุงู OpenAI ----------
def analyze_text_with_gpt(text, model, api_key):
    client = OpenAI(api_key=api_key)
    prompt = generate_prompt(text)

    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "ุฃูุช ูุณุงุนุฏ ุฐูู ูุชุฎุตุต ูู ุชุญููู ุงููุตูุต ุงูุดุฑุนูุฉ ูุงุณุชุฎุฑุงุฌ ุงููุดุงูุงุช ุงูุนูููุฉ ูููุง ุจุฏูุฉ."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2
    )

    return response.choices[0].message.content.strip()

# ---------- ุชูุณูู ุงููุต ุญุณุจ ุฃุฑูุงู ุงูุตูุญุงุช ----------
def split_text_by_page(text):
    pattern = r"</<(\d+)>"
    parts = re.split(pattern, text)
    
    page_chunks = []
    for i in range(1, len(parts), 2):
        page_number = int(parts[i])
        content = parts[i+1].strip()
        page_chunks.append({
            "page": page_number,
            "content": content
        })
    return page_chunks

# ---------- ุชุญุฏูุฏ ุฑูู ุงูุตูุญุฉ ุจูุงุกู ุนูู ูุทูุน ุงูููุฑุฉ ----------
def find_page_for_excerpt(excerpt, page_chunks):
    for chunk in page_chunks:
        if excerpt in chunk["content"]:
            return chunk["page"]
    return "ุบูุฑ ูุนุฑูู"

# ---------- ุชุญููู ูุฎุฑุฌุงุช ุงููููุฐุฌ ุฅูู DataFrame ----------
def parse_response_to_df(response_text, page_chunks):
    rows = []
    lines = response_text.strip().splitlines()

    for line in lines:
        parts = [part.strip() for part in line.split("|")]
        if len(parts) >= 4:
            excerpt = parts[0]
            page = find_page_for_excerpt(excerpt, page_chunks)

            rows.append({
                "ูุทูุน ุงูููุฑุฉ": excerpt,
                "ููุน ุงููุดุงู": parts[1],
                "ุนููุงู ุงููุดุงู": parts[2],
                "ุณุจุจ ุงูุชุตููู": parts[3],
                "ุฑูู ุงูุตูุญุฉ": page
            })

    return pd.DataFrame(rows)

# ---------- ุชูููุฐ ุงูุชุญููู ----------
if st.button("๐ ุชุญููู ุงููุต") and uploaded_file and openai_key:
    with st.spinner("ุฌุงุฑู ุชุญููู ุงููุต..."):
        try:
            full_text = extract_full_text(uploaded_file)
            page_chunks = split_text_by_page(full_text)
            response_text = analyze_text_with_gpt(full_text, model_choice, openai_key)
            df = parse_response_to_df(response_text, page_chunks)

            # ุญูุธ ููู ุฅูุณู
            excel_io = BytesIO()
            df.to_excel(excel_io, index=False)
            st.session_state.excel_output = excel_io

            st.success("โ ุชู ุงุณุชุฎุฑุงุฌ ุงููุดุงูุงุช ุจูุฌุงุญ!")
            st.dataframe(df)

        except Exception as e:
            st.error(f"ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุงูุชุญููู: {e}")

# ---------- ุฒุฑ ุงูุชุญููู ----------
if st.session_state.excel_output:
    st.download_button(
        label="๐ฅ ุชุญููู ููู Excel",
        data=st.session_state.excel_output.getvalue(),
        file_name="kashafaat.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
